{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image inversion with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert PIL image to 200x200 array normalised to -0.5 to 0.5 rage.\n",
    "def image_2_array(filename):\n",
    "    # PIL image pil_img\n",
    "    pil_img=Image.open(filename)\n",
    "    pil_arr=np.array(pil_img)\n",
    "    pil_max = np.amax(np.absolute(pil_arr))\n",
    "    pil_min = np.amin(np.absolute(pil_arr))\n",
    "    #print (\"Max/min:\"+ str(pil_max)+\"/\"+str(pil_min))\n",
    "    if pil_max == 0:\n",
    "        return pil_img,pil_arr\n",
    "    pil_scaled_arr = (pil_arr / pil_max) - 0.5\n",
    "    return pil_img,pil_scaled_arr\n",
    "\n",
    "# Invert normalised PIL image\n",
    "def invert_array(arr):\n",
    "    #print(arr.shape)\n",
    "    #print(arr[100][50:60])\n",
    "    inverted_arr = arr * (-1)\n",
    "    #print(inverted_arr[100][50:60])\n",
    "    return inverted_arr\n",
    "    \n",
    "# Convert normalized array to PIL image\n",
    "def array_2_image(arr):\n",
    "    MAX = 255\n",
    "    arr_scaled = (arr + 0.5) * MAX\n",
    "    arr_max = np.amax(arr_scaled)\n",
    "    arr_min = np.amin(arr_scaled)\n",
    "    #print (\"Array Max/min:\"+ str(arr_max)+\"/\"+str(arr_min))\n",
    "    im = Image.fromarray(arr_scaled)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Image inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare inversed images\n",
    "plot = False\n",
    "save = False  # Only need to save once\n",
    "if save:\n",
    "    for dataset in range(1, 11):\n",
    "        for img_counter in range(1, 11):\n",
    "            # Read Image\n",
    "            dataset_str = str(dataset).zfill(3)\n",
    "            image_str = str(img_counter).zfill(4)\n",
    "            filename = \"/notebooks/data001/move\" + \\\n",
    "                    dataset_str+\"_\"+image_str+\".gif\"\n",
    "            #print filename\n",
    "            img,a = image_2_array(filename)\n",
    "            #print(\"Orgarr:\")\n",
    "            #print(a)\n",
    "\n",
    "\n",
    "            in_arr = invert_array(a)\n",
    "            #print(\"Invarr:\")\n",
    "            #print(in_arr)\n",
    "            new_im = array_2_image(in_arr)\n",
    "            new_filename = \"/notebooks/data001/move_inv_\" + \\\n",
    "                    dataset_str+\"_\"+image_str+\".gif\"\n",
    "            # Save new image to file\n",
    "            new_im.save(new_filename, \"GIF\")\n",
    "            # Plot\n",
    "            if (plot):\n",
    "                _, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "                ax1.imshow(img);\n",
    "                ax2.imshow(a, vmin=-0.5, vmax=0.5,cmap=plt.cm.Greys);\n",
    "                ax3.imshow(in_arr, cmap=plt.cm.Greys);\n",
    "                ax4.imshow(new_im);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/data001/move001_0001.gif\n",
      "/notebooks/data001/move_inv_001_0001.gif\n",
      "/notebooks/data001/move001_0002.gif\n",
      "/notebooks/data001/move_inv_001_0002.gif\n",
      "/notebooks/data001/move001_0003.gif\n",
      "/notebooks/data001/move_inv_001_0003.gif\n",
      "/notebooks/data001/move001_0004.gif\n",
      "/notebooks/data001/move_inv_001_0004.gif\n",
      "/notebooks/data001/move001_0005.gif\n",
      "/notebooks/data001/move_inv_001_0005.gif\n",
      "/notebooks/data001/move001_0006.gif\n",
      "/notebooks/data001/move_inv_001_0006.gif\n",
      "/notebooks/data001/move001_0007.gif\n",
      "/notebooks/data001/move_inv_001_0007.gif\n",
      "/notebooks/data001/move001_0008.gif\n",
      "/notebooks/data001/move_inv_001_0008.gif\n",
      "/notebooks/data001/move001_0009.gif\n",
      "/notebooks/data001/move_inv_001_0009.gif\n",
      "/notebooks/data001/move001_0010.gif\n",
      "/notebooks/data001/move_inv_001_0010.gif\n",
      "/notebooks/data001/move002_0001.gif\n",
      "/notebooks/data001/move_inv_002_0001.gif\n",
      "/notebooks/data001/move002_0002.gif\n",
      "/notebooks/data001/move_inv_002_0002.gif\n",
      "/notebooks/data001/move002_0003.gif\n",
      "/notebooks/data001/move_inv_002_0003.gif\n",
      "/notebooks/data001/move002_0004.gif\n",
      "/notebooks/data001/move_inv_002_0004.gif\n",
      "/notebooks/data001/move002_0005.gif\n",
      "/notebooks/data001/move_inv_002_0005.gif\n",
      "/notebooks/data001/move002_0006.gif\n",
      "/notebooks/data001/move_inv_002_0006.gif\n",
      "/notebooks/data001/move002_0007.gif\n",
      "/notebooks/data001/move_inv_002_0007.gif\n",
      "/notebooks/data001/move002_0008.gif\n",
      "/notebooks/data001/move_inv_002_0008.gif\n",
      "/notebooks/data001/move002_0009.gif\n",
      "/notebooks/data001/move_inv_002_0009.gif\n",
      "/notebooks/data001/move002_0010.gif\n",
      "/notebooks/data001/move_inv_002_0010.gif\n",
      "/notebooks/data001/move003_0001.gif\n",
      "/notebooks/data001/move_inv_003_0001.gif\n",
      "/notebooks/data001/move003_0002.gif\n",
      "/notebooks/data001/move_inv_003_0002.gif\n",
      "/notebooks/data001/move003_0003.gif\n",
      "/notebooks/data001/move_inv_003_0003.gif\n",
      "/notebooks/data001/move003_0004.gif\n",
      "/notebooks/data001/move_inv_003_0004.gif\n",
      "/notebooks/data001/move003_0005.gif\n",
      "/notebooks/data001/move_inv_003_0005.gif\n",
      "/notebooks/data001/move003_0006.gif\n",
      "/notebooks/data001/move_inv_003_0006.gif\n",
      "/notebooks/data001/move003_0007.gif\n",
      "/notebooks/data001/move_inv_003_0007.gif\n",
      "/notebooks/data001/move003_0008.gif\n",
      "/notebooks/data001/move_inv_003_0008.gif\n",
      "/notebooks/data001/move003_0009.gif\n",
      "/notebooks/data001/move_inv_003_0009.gif\n",
      "/notebooks/data001/move003_0010.gif\n",
      "/notebooks/data001/move_inv_003_0010.gif\n",
      "/notebooks/data001/move004_0001.gif\n",
      "/notebooks/data001/move_inv_004_0001.gif\n",
      "/notebooks/data001/move004_0002.gif\n",
      "/notebooks/data001/move_inv_004_0002.gif\n",
      "/notebooks/data001/move004_0003.gif\n",
      "/notebooks/data001/move_inv_004_0003.gif\n",
      "/notebooks/data001/move004_0004.gif\n",
      "/notebooks/data001/move_inv_004_0004.gif\n",
      "/notebooks/data001/move004_0005.gif\n",
      "/notebooks/data001/move_inv_004_0005.gif\n",
      "/notebooks/data001/move004_0006.gif\n",
      "/notebooks/data001/move_inv_004_0006.gif\n",
      "/notebooks/data001/move004_0007.gif\n",
      "/notebooks/data001/move_inv_004_0007.gif\n",
      "/notebooks/data001/move004_0008.gif\n",
      "/notebooks/data001/move_inv_004_0008.gif\n",
      "/notebooks/data001/move004_0009.gif\n",
      "/notebooks/data001/move_inv_004_0009.gif\n",
      "/notebooks/data001/move004_0010.gif\n",
      "/notebooks/data001/move_inv_004_0010.gif\n",
      "/notebooks/data001/move005_0001.gif\n",
      "/notebooks/data001/move_inv_005_0001.gif\n",
      "/notebooks/data001/move005_0002.gif\n",
      "/notebooks/data001/move_inv_005_0002.gif\n",
      "/notebooks/data001/move005_0003.gif\n",
      "/notebooks/data001/move_inv_005_0003.gif\n",
      "/notebooks/data001/move005_0004.gif\n",
      "/notebooks/data001/move_inv_005_0004.gif\n",
      "/notebooks/data001/move005_0005.gif\n",
      "/notebooks/data001/move_inv_005_0005.gif\n",
      "/notebooks/data001/move005_0006.gif\n",
      "/notebooks/data001/move_inv_005_0006.gif\n",
      "/notebooks/data001/move005_0007.gif\n",
      "/notebooks/data001/move_inv_005_0007.gif\n",
      "/notebooks/data001/move005_0008.gif\n",
      "/notebooks/data001/move_inv_005_0008.gif\n",
      "/notebooks/data001/move005_0009.gif\n",
      "/notebooks/data001/move_inv_005_0009.gif\n",
      "/notebooks/data001/move005_0010.gif\n",
      "/notebooks/data001/move_inv_005_0010.gif\n",
      "/notebooks/data001/move006_0001.gif\n",
      "/notebooks/data001/move_inv_006_0001.gif\n",
      "/notebooks/data001/move006_0002.gif\n",
      "/notebooks/data001/move_inv_006_0002.gif\n",
      "/notebooks/data001/move006_0003.gif\n",
      "/notebooks/data001/move_inv_006_0003.gif\n",
      "/notebooks/data001/move006_0004.gif\n",
      "/notebooks/data001/move_inv_006_0004.gif\n",
      "/notebooks/data001/move006_0005.gif\n",
      "/notebooks/data001/move_inv_006_0005.gif\n",
      "/notebooks/data001/move006_0006.gif\n",
      "/notebooks/data001/move_inv_006_0006.gif\n",
      "/notebooks/data001/move006_0007.gif\n",
      "/notebooks/data001/move_inv_006_0007.gif\n",
      "/notebooks/data001/move006_0008.gif\n",
      "/notebooks/data001/move_inv_006_0008.gif\n",
      "/notebooks/data001/move006_0009.gif\n",
      "/notebooks/data001/move_inv_006_0009.gif\n",
      "/notebooks/data001/move006_0010.gif\n",
      "/notebooks/data001/move_inv_006_0010.gif\n",
      "/notebooks/data001/move007_0001.gif\n",
      "/notebooks/data001/move_inv_007_0001.gif\n",
      "/notebooks/data001/move007_0002.gif\n",
      "/notebooks/data001/move_inv_007_0002.gif\n",
      "/notebooks/data001/move007_0003.gif\n",
      "/notebooks/data001/move_inv_007_0003.gif\n",
      "/notebooks/data001/move007_0004.gif\n",
      "/notebooks/data001/move_inv_007_0004.gif\n",
      "/notebooks/data001/move007_0005.gif\n",
      "/notebooks/data001/move_inv_007_0005.gif\n",
      "/notebooks/data001/move007_0006.gif\n",
      "/notebooks/data001/move_inv_007_0006.gif\n",
      "/notebooks/data001/move007_0007.gif\n",
      "/notebooks/data001/move_inv_007_0007.gif\n",
      "/notebooks/data001/move007_0008.gif\n",
      "/notebooks/data001/move_inv_007_0008.gif\n",
      "/notebooks/data001/move007_0009.gif\n",
      "/notebooks/data001/move_inv_007_0009.gif\n",
      "/notebooks/data001/move007_0010.gif\n",
      "/notebooks/data001/move_inv_007_0010.gif\n",
      "/notebooks/data001/move008_0001.gif\n",
      "/notebooks/data001/move_inv_008_0001.gif\n",
      "/notebooks/data001/move008_0002.gif\n",
      "/notebooks/data001/move_inv_008_0002.gif\n",
      "/notebooks/data001/move008_0003.gif\n",
      "/notebooks/data001/move_inv_008_0003.gif\n",
      "/notebooks/data001/move008_0004.gif\n",
      "/notebooks/data001/move_inv_008_0004.gif\n",
      "/notebooks/data001/move008_0005.gif\n",
      "/notebooks/data001/move_inv_008_0005.gif\n",
      "/notebooks/data001/move008_0006.gif\n",
      "/notebooks/data001/move_inv_008_0006.gif\n",
      "/notebooks/data001/move008_0007.gif\n",
      "/notebooks/data001/move_inv_008_0007.gif\n",
      "/notebooks/data001/move008_0008.gif\n",
      "/notebooks/data001/move_inv_008_0008.gif\n",
      "/notebooks/data001/move008_0009.gif\n",
      "/notebooks/data001/move_inv_008_0009.gif\n",
      "/notebooks/data001/move008_0010.gif\n",
      "/notebooks/data001/move_inv_008_0010.gif\n",
      "(3200000,)\n",
      "(3200000,)\n",
      "80\n",
      "(80, 200, 200, 1)\n",
      "(80, 200, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read training images into array of shape (80, 200, 200, 1)\n",
    "IMSIZE=200\n",
    "train_data_onedimension = np.array([]) #np.empty([80,200,200,1])\n",
    "train_labl_onedimension = np.array([])\n",
    "for dataset in range(1, 9):\n",
    "    for img_counter in range(1, 11):\n",
    "        dataset_str = str(dataset).zfill(3)\n",
    "        image_str = str(img_counter).zfill(4)\n",
    "        # Samples\n",
    "        filename = \"/notebooks/data001/move\" + \\\n",
    "                dataset_str+\"_\"+image_str+\".gif\"\n",
    "        print filename\n",
    "        img,a = image_2_array(filename)\n",
    "        \n",
    "        train_data_onedimension = np.append(train_data_onedimension,a)\n",
    "        # Targets (labels)\n",
    "        filename = \"/notebooks/data001/move_inv_\" + \\\n",
    "                dataset_str+\"_\"+image_str+\".gif\"\n",
    "        print filename\n",
    "        img,a = image_2_array(filename)\n",
    "        train_labl_onedimension = np.append(train_labl_onedimension,a)\n",
    "        \n",
    "        \n",
    "print train_data_onedimension.shape\n",
    "print train_labl_onedimension.shape\n",
    "\n",
    "images_in_set = train_data_onedimension.size / (IMSIZE*IMSIZE)\n",
    "print images_in_set\n",
    "train_data = train_data_onedimension.reshape(images_in_set, IMSIZE, IMSIZE, 1)\n",
    "print train_data.shape\n",
    "train_labl = train_labl_onedimension.reshape(images_in_set, IMSIZE, IMSIZE, 1)\n",
    "print train_labl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newral Network \n",
    "\n",
    "L – Number of layers = 3\n",
    "\n",
    "$s_j$ – кол-во элементов в слое j\n",
    "\n",
    "Кол-во элементов по слоям:\n",
    "$s_1$ = 40000\n",
    "$s_2$ = 40000\n",
    "$s_3$ = 40000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40000, 40000, 40000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 3\n",
    "s = np.ones(L, dtype=np.int) * IMSIZE*IMSIZE\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random $\\Theta$ initialisation\n",
    "\n",
    "$\\epsilon=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "40000\n",
      "2\n",
      "40000\n",
      "[array([[ 0.04019491,  0.00877941,  0.28164199, ..., -0.29980837,\n",
      "        -0.05458793, -0.13429882],\n",
      "       [ 0.27307652,  0.19263834,  0.45375294, ...,  0.08290362,\n",
      "        -0.33900697,  0.22474366],\n",
      "       [-0.40393647,  0.20432185,  0.0694239 , ...,  0.07500261,\n",
      "        -0.21728321, -0.37293107],\n",
      "       ..., \n",
      "       [ 0.37316968,  0.03458426, -0.41070868, ...,  0.356509  ,\n",
      "         0.37365916, -0.35365806],\n",
      "       [ 0.29708414, -0.09842149, -0.36000103, ..., -0.08217825,\n",
      "         0.39726725,  0.28294943],\n",
      "       [-0.20899501, -0.42017115,  0.36603819, ..., -0.00825868,\n",
      "        -0.11170189,  0.29392853]]), array([[-0.44497826,  0.10997881, -0.3227901 , ...,  0.14463931,\n",
      "         0.34160487, -0.45184907],\n",
      "       [-0.11444854,  0.06083013, -0.11166088, ..., -0.23592035,\n",
      "         0.12838341,  0.37345527],\n",
      "       [ 0.2840222 ,  0.22242093, -0.06866587, ..., -0.1150945 ,\n",
      "        -0.07154383, -0.42332406],\n",
      "       ..., \n",
      "       [ 0.00730122,  0.37400741,  0.17107083, ...,  0.03738642,\n",
      "         0.14752907,  0.05296655],\n",
      "       [-0.43129339,  0.25884267,  0.12111416, ..., -0.47972852,\n",
      "         0.41239394, -0.25159563],\n",
      "       [-0.22181506,  0.03430808,  0.41805191, ...,  0.1140425 ,\n",
      "        -0.17939186,  0.04063567]])]\n"
     ]
    }
   ],
   "source": [
    "INIT_EPSILON=0.5\n",
    "Theta = []\n",
    "for j in range(1,L):\n",
    "    print(j)\n",
    "    print(s[j-1])\n",
    "    theta = np.random.rand(s[j],s[j-1]+1) * (2*INIT_EPSILON) - INIT_EPSILON\n",
    "    Theta.append(theta) \n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Note: Access $\\Theta_1$ as `Theta[0]`, $\\Theta_2$ as `Theta[1]`._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regularisation computations use matrix $\\Theta$ without first (bias) column. Store it in list of arrays `Theta_r`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-a71ee79f0505>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-a71ee79f0505>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    Theta1_red = Theta[0](:, 2:input_layer_size+1);\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Return cost and gradient for given Theta.\n",
    "# Parameters:\n",
    "# Theta – weights,\n",
    "# L – number of layers in NN,\n",
    "# s – number of elements in each layer,\n",
    "# X – training dataset,\n",
    "# Y – target dataset,\n",
    "# lmbd – regularisation parameter lambda.\n",
    "def costFunction(Theta, L, s, X, Y, lmbd):\n",
    "    # Initialisation. Need to return the following variables:\n",
    "    J = 0;\n",
    "    Theta_grad = []\n",
    "    for j in range(1,L):\n",
    "        Theta_grad.append(np.zeros(size(Theta[j-1]))\n",
    "                          \n",
    "    # Remove first column from Theta1\n",
    "    Theta_r = []\n",
    "    for j in range(1,L):\n",
    "        theta_reduced = Theta[j-1][:, 1:]\n",
    "        Theta_r.append(theta_reduced)\n",
    "        print(Theta_r[j-1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-943645028040>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-943645028040>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    x[,0:2]\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1],[2],[3]], [[4],[5],[6]]])\n",
    "x.shape\n",
    "x[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
